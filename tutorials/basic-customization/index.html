<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Basic Customization | AI, LLM &amp; LLM-HypatiaX Blog</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Basic Customization" />
<meta name="author" content="Dr. Ruperto Pedro Bonet Chaple" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Overview on Fundamental Customization Techniques" />
<meta property="og:description" content="Overview on Fundamental Customization Techniques" />
<link rel="canonical" href="https://sednabcn.github.io/ai-llm-blog/tutorials/basic-customization/" />
<meta property="og:url" content="https://sednabcn.github.io/ai-llm-blog/tutorials/basic-customization/" />
<meta property="og:site_name" content="AI, LLM &amp; LLM-HypatiaX Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-04-15T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Basic Customization" />
<meta name="google-site-verification" content="0l5TbPYQ76ChPVEmXUclBOY04jLkGAAQAKAEm2a0j60" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Dr. Ruperto Pedro Bonet Chaple"},"dateModified":"2025-04-15T00:00:00+00:00","datePublished":"2025-04-15T00:00:00+00:00","description":"Overview on Fundamental Customization Techniques","headline":"Basic Customization","mainEntityOfPage":{"@type":"WebPage","@id":"https://sednabcn.github.io/ai-llm-blog/tutorials/basic-customization/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://sednabcn.github.io/ai-llm-blog/assets/images/logo.png"},"name":"Dr. Ruperto Pedro Bonet Chaple"},"url":"https://sednabcn.github.io/ai-llm-blog/tutorials/basic-customization/"}</script>
<!-- End Jekyll SEO tag -->

    
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Basic Customization</title>

  <!-- SEO -->
  <!-- begin _includes/seo.html --><title>Basic Customization | AI, LLM &amp; LLM-HypatiaX Blog</title>
<meta name="description" content="Overview  on Fundamental Customization Techniques">


  <meta name="author" content="Dr. Ruperto Pedro Bonet Chaple">
  
  <meta property="article:author" content="Dr. Ruperto Pedro Bonet Chaple">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="AI, LLM & LLM-HypatiaX Blog">
<meta property="og:title" content="Basic Customization">
<meta property="og:url" content="https://sednabcn.github.io/ai-llm-blog/tutorials/basic-customization/">


  <meta property="og:description" content="Overview  on Fundamental Customization Techniques">



  <meta property="og:image" content="https://sednabcn.github.io/ai-llm-blog/assets/images/tutorials/tutorials-banner.webp">





  <meta property="article:published_time" content="2025-04-15T00:00:00+00:00">






<link rel="canonical" href="https://sednabcn.github.io/ai-llm-blog/tutorials/basic-customization/">







  <meta name="google-site-verification" content="0l5TbPYQ76ChPVEmXUclBOY04jLkGAAQAKAEm2a0j60" />






<!-- end _includes/seo.html -->


  <!-- Atom Feed -->
  
    <link href="/ai-llm-blog/feed.xml" 
          type="application/atom+xml" rel="alternate" title="AI, LLM & LLM-HypatiaX Blog Feed">
  

  <!-- Favicon -->
  <link rel="icon" href="/ai-llm-blog/favicon-16x16.png" type="image/png">

  <!-- JavaScript Detection -->
  <script>
    document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
    
  </script>

  <!-- Stylesheets -->
  
    <link rel="stylesheet" href="/ai-llm-blog/assets/css/main.css">
  

  
  <!-- Stylesheets -->
  
    <link rel="stylesheet" href="/ai-llm-blog/assets/css/main-mobiles.css">
  


  <!-- Font Awesome (with performance optimization) -->
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" 
        as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">
  </noscript>

  <!-- Google Site Verification -->
  
    <meta name="google-site-verification" content="0l5TbPYQ76ChPVEmXUclBOY04jLkGAAQAKAEm2a0j60">
  

  
 
 <!-- Content Security Policy -->
<meta http-equiv="Content-Security-Policy" content="
  default-src 'self';
  script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.jsdelivr.net/ https://www.googletagmanager.com/ https://www.google-analytics.com/ https://utteranc.es;
  style-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net/;
  img-src 'self' data: *;
  font-src 'self' https://cdn.jsdelivr.net/;
  connect-src 'self' https://utteranc.es https://region1.google-analytics.com https://www.google-analytics.com;
  frame-src 'self' https://utteranc.es;
"> 
  <!-- Custom Head Scripts -->
  

  <!-- Analytics (production only) -->
  
    


  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FFJMQ3HXMK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FFJMQ3HXMK', { 'anonymize_ip': true});
</script>




  

 <!-- Open Graph / Facebook -->
<meta property="og:type" content="article">
<meta property="og:url" content="https://sednabcn.github.io/tutorials/basic-customization/">
<meta property="og:title" content="Basic Customization">
<meta property="og:description" content="Overview  on Fundamental Customization Techniques">


<!-- Twitter -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:url" content="https://sednabcn.github.io/tutorials/basic-customization/">
<meta name="twitter:title" content="Basic Customization">
<meta name="twitter:description" content="Overview  on Fundamental Customization Techniques">


</head>

    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single -inner-page -header-image-readability" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/ai-llm-blog/"><img src="/ai-llm-blog/assets/images/logo.png" alt="SiMLeng"></a>
        
        <a class="site-title" href="/ai-llm-blog/">
          SiMLeng
          <span class="site-subtitle">Exploring generative AI in formula discovery</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/ai-llm-blog/"
                
                
              >Home</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-llm-blog/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-llm-blog/posts/"
                
                
              >Posts</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-llm-blog/tutorials/"
                
                
              >Tutorials</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-llm-blog/help/"
                
                
              >Help</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: linear-gradient(rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 0.5)), url('/ai-llm-blog/assets/images/tutorials/tutorials-banner.webp');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Basic Customization

        
      </h1>
      
     <span class="page__lead excerpt-inline">Overview  on Fundamental Customization Techniques</span>

    <!--- <p class="page__lead" style="text-align: center;">Overview  on Fundamental Customization Techniques
</p>--!>
      
      


      
    </div>
  
  
</div>










<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="https://sednabcn.github.io/ai-llm-blog/">
        <img src="/ai-llm-blog/assets/images/avatar.jpg" alt="Dr. Ruperto Pedro Bonet Chaple" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="https://sednabcn.github.io/ai-llm-blog/" itemprop="url">Dr. Ruperto Pedro Bonet Chaple</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>PhD in Computational Mechanics</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">London, UK</span>
        </li>
      

      
        
          
            <li><a href="mailto:info@modelphysmat.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://github.com/sednabcn" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/ruperto-p-bonet-chaple-8a26651b/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    
      <meta itemprop="headline" content="Basic Customization">
    
    
      <meta itemprop="description" content="Overview  on Fundamental Customization Techniques">
    
    
      <meta itemprop="datePublished" content="2025-04-15T00:00:00+00:00">
    
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header>
                <h4 class="nav__title">
                  <i class="fas fa-question-circle"></i> customization Topics
                </h4>
              </header>
              <ul class="toc__menu"><li><a href="#basic-customization">Basic Customization</a></li><li><a href="#understanding-model-customization">Understanding Model Customization</a></li><li><a href="#1-prompt-engineering-basics">1. Prompt Engineering Basics</a><ul><li><a href="#prompt-structure">Prompt Structure</a></li><li><a href="#basic-prompt-templates">Basic Prompt Templates</a></li><li><a href="#prompt-optimization-techniques">Prompt Optimization Techniques</a></li><li><a href="#example-improving-a-basic-prompt">Example: Improving a Basic Prompt</a></li></ul></li><li><a href="#2-few-shot-learning">2. Few-Shot Learning</a><ul><li><a href="#example-few-shot-classification">Example: Few-shot Classification</a></li><li><a href="#guidelines-for-effective-few-shot-learning">Guidelines for Effective Few-Shot Learning</a></li></ul></li><li><a href="#3-basic-fine-tuning">3. Basic Fine-tuning</a><ul><li><a href="#when-to-fine-tune">When to Fine-tune</a></li><li><a href="#preparing-your-dataset">Preparing Your Dataset</a></li><li><a href="#fine-tuning-with-hugging-face">Fine-tuning with Hugging Face</a></li><li><a href="#parameter-efficient-fine-tuning-peft">Parameter-Efficient Fine-tuning (PEFT)</a></li></ul></li><li><a href="#4-retrieval-augmented-generation-rag">4. Retrieval-Augmented Generation (RAG)</a><ul><li><a href="#basic-rag-implementation">Basic RAG Implementation</a></li><li><a href="#key-components-of-rag">Key Components of RAG</a></li></ul></li><li><a href="#5-customizing-output-formats">5. Customizing Output Formats</a><ul><li><a href="#json-output">JSON Output</a></li><li><a href="#markdown-formatting">Markdown Formatting</a></li><li><a href="#custom-templates">Custom Templates</a></li></ul></li><li><a href="#6-model-evaluation">6. Model Evaluation</a><ul><li><a href="#basic-evaluation-metrics">Basic Evaluation Metrics</a></li><li><a href="#evaluation-code-example">Evaluation Code Example</a></li></ul></li><li><a href="#next-steps">Next Steps</a></li><li><a href="#happy-customizing">Happy customizing!</a></li></ul>
            </nav>
          </aside>
        
        <h2 id="basic-customization">Basic Customization</h2>

<p>This tutorial will guide you through the fundamental customization techniques for adapting Large Language Models (LLMs) to better suit your specific needs and use cases.</p>

<h2 id="understanding-model-customization">Understanding Model Customization</h2>

<p>Before diving into technical details, let’s understand the spectrum of customization options:</p>

<ul>
  <li><strong>Prompt Engineering</strong>: Lightweight, no model changes</li>
  <li><strong>Few-shot Learning</strong>: Using examples in prompts</li>
  <li><strong>Fine-tuning</strong>: Updating model weights</li>
  <li><strong>Adapter Methods</strong>: Adding small trainable components</li>
  <li><strong>Retrieval Augmentation</strong>: Enhancing models with external knowledge</li>
</ul>

<h2 id="1-prompt-engineering-basics">1. Prompt Engineering Basics</h2>

<p>Prompt engineering is the art and science of crafting inputs to get desired outputs from LLMs.</p>

<h3 id="prompt-structure">Prompt Structure</h3>

<p>Effective prompts typically include:</p>
<ul>
  <li>Clear instructions</li>
  <li>Context/background information</li>
  <li>Format specification</li>
  <li>Examples (optional)</li>
  <li>Constraints or requirements</li>
</ul>

<h3 id="basic-prompt-templates">Basic Prompt Templates</h3>

<p><strong>Question Answering:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Answer the following question accurately and concisely:
[QUESTION]
</code></pre></div></div>

<p><strong>Content Generation:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Write a [CONTENT TYPE] about [TOPIC] in the style of [STYLE]. The [CONTENT TYPE] should include [REQUIREMENTS].
</code></pre></div></div>

<p><strong>Classification:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Classify the following text into one of these categories: [CATEGORY LIST]

Text: [TEXT]
</code></pre></div></div>

<h3 id="prompt-optimization-techniques">Prompt Optimization Techniques</h3>

<ol>
  <li><strong>Be Specific</strong>: Clearly define what you want</li>
  <li><strong>Provide Context</strong>: Give background information</li>
  <li><strong>Control Output Format</strong>: Specify how results should be structured</li>
  <li><strong>Use System Messages</strong>: Set the tone and role where supported</li>
  <li><strong>Chain of Thought</strong>: Ask the model to reason step-by-step</li>
</ol>

<h3 id="example-improving-a-basic-prompt">Example: Improving a Basic Prompt</h3>

<p><strong>Basic Prompt:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Summarize this article.
</code></pre></div></div>

<p><strong>Improved Prompt:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Summarize the following article in 3-5 bullet points, focusing on the key findings and implications. Each bullet point should be 1-2 sentences long.

Article: [ARTICLE TEXT]
</code></pre></div></div>

<h2 id="2-few-shot-learning">2. Few-Shot Learning</h2>

<p>Few-shot learning involves providing examples within the prompt to demonstrate the desired pattern.</p>

<h3 id="example-few-shot-classification">Example: Few-shot Classification</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Classify the following customer feedback as Positive, Neutral, or Negative.

Example 1:
Feedback: "Your product completely solved my problem! I'm amazed at how well it works."
Classification: Positive

Example 2:
Feedback: "The product works as described but the setup process was confusing."
Classification: Neutral

Example 3:
Feedback: "This is the worst experience I've ever had. Nothing works as advertised."
Classification: Negative

Now classify this feedback:
Feedback: "[NEW FEEDBACK]"
Classification:
</code></pre></div></div>

<h3 id="guidelines-for-effective-few-shot-learning">Guidelines for Effective Few-Shot Learning</h3>

<ol>
  <li><strong>Use Diverse Examples</strong>: Cover different cases and patterns</li>
  <li><strong>Match Example Format to Target</strong>: Use similar complexity and structure</li>
  <li><strong>Order Matters</strong>: Consider example sequence (simple to complex often works well)</li>
  <li><strong>Quality Over Quantity</strong>: 3-5 well-chosen examples often suffice</li>
</ol>

<h2 id="3-basic-fine-tuning">3. Basic Fine-tuning</h2>

<p>Fine-tuning adapts a pre-trained model to specific domains or tasks by updating its weights with new training data.</p>

<h3 id="when-to-fine-tune">When to Fine-tune</h3>

<p>Consider fine-tuning when:</p>
<ul>
  <li>You need consistent outputs in a specialized domain</li>
  <li>You have a specific task with available training data</li>
  <li>Prompt engineering alone doesn’t achieve desired results</li>
  <li>You need to reduce prompt length for efficiency</li>
</ul>

<h3 id="preparing-your-dataset">Preparing Your Dataset</h3>

<p>A quality dataset is crucial for successful fine-tuning:</p>

<ol>
  <li><strong>Format Your Data</strong>: Most frameworks use instruction-response pairs:
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"instruction"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Classify this news headline as business, sports, entertainment, or politics"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"input"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Tesla Stock Soars After Earnings Report"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"output"</span><span class="p">:</span><span class="w"> </span><span class="s2">"business"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><strong>Dataset Size Guidelines</strong>:
    <ul>
      <li>Small models: 100-1000+ examples</li>
      <li>Medium models: 500-5000+ examples</li>
      <li>Large models: 1000-10000+ examples</li>
    </ul>
  </li>
  <li><strong>Data Quality Checks</strong>:
    <ul>
      <li>Ensure diversity in examples</li>
      <li>Check for biases or problematic content</li>
      <li>Validate consistency in formatting</li>
      <li>Split into training/validation sets (80%/20%)</li>
    </ul>
  </li>
</ol>

<h3 id="fine-tuning-with-hugging-face">Fine-tuning with Hugging Face</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="c1"># Load model and tokenizer
</span><span class="n">model_name</span> <span class="o">=</span> <span class="s">"meta-llama/Llama-2-7b-hf"</span>  <span class="c1"># Example model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="c1"># Prepare dataset
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s">"json"</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s">"your_dataset.json"</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">"max_length"</span><span class="p">))</span>

<span class="c1"># Define training arguments
</span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s">"./fine-tuned-model"</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Initialize Trainer
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s">"train"</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s">"validation"</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1"># Start fine-tuning
</span><span class="n">trainer</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># Save the model
</span><span class="n">model</span><span class="p">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s">"./fine-tuned-model"</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s">"./fine-tuned-model"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="parameter-efficient-fine-tuning-peft">Parameter-Efficient Fine-tuning (PEFT)</h3>

<p>For resource-constrained environments, consider PEFT methods:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">TaskType</span>

<span class="c1"># Define LoRA configuration
</span><span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="p">.</span><span class="n">CAUSAL_LM</span><span class="p">,</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># Rank
</span>    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s">"q_proj"</span><span class="p">,</span> <span class="s">"v_proj"</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Get PEFT model
</span><span class="n">peft_model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>

<span class="c1"># Continue with training as above, but using peft_model instead of model
</span></code></pre></div></div>

<h2 id="4-retrieval-augmented-generation-rag">4. Retrieval-Augmented Generation (RAG)</h2>

<p>RAG enhances LLMs by retrieving relevant information from external sources to inform responses.</p>

<h3 id="basic-rag-implementation">Basic RAG Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>
<span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">RetrievalQA</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>

<span class="c1"># Load documents
</span><span class="n">documents</span> <span class="o">=</span> <span class="n">TextLoader</span><span class="p">(</span><span class="s">"your_knowledge_base.txt"</span><span class="p">).</span><span class="n">load</span><span class="p">()</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">chunks</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

<span class="c1"># Create embeddings and vector store
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceEmbeddings</span><span class="p">()</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="p">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>

<span class="c1"># Set up retrieval chain
</span><span class="n">qa_chain</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="n">from_chain_type</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">HuggingFacePipeline</span><span class="p">.</span><span class="n">from_model_id</span><span class="p">(</span>
        <span class="n">model_id</span><span class="o">=</span><span class="s">"your-fine-tuned-model"</span><span class="p">,</span>
        <span class="n">task</span><span class="o">=</span><span class="s">"text-generation"</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">chain_type</span><span class="o">=</span><span class="s">"stuff"</span><span class="p">,</span>
    <span class="n">retriever</span><span class="o">=</span><span class="n">vectorstore</span><span class="p">.</span><span class="n">as_retriever</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># Query the system
</span><span class="n">response</span> <span class="o">=</span> <span class="n">qa_chain</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="s">"What is the capital of France?"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="key-components-of-rag">Key Components of RAG</h3>

<ol>
  <li><strong>Document Processing</strong>: Chunking text into manageable pieces</li>
  <li><strong>Embedding Generation</strong>: Converting text chunks to vector representations</li>
  <li><strong>Vector Storage</strong>: Efficient storage and retrieval of embeddings</li>
  <li><strong>Similarity Search</strong>: Finding relevant content for a query</li>
  <li><strong>Response Generation</strong>: Synthesizing retrieved information into coherent answers</li>
</ol>

<h2 id="5-customizing-output-formats">5. Customizing Output Formats</h2>

<p>Control how your model structures its responses:</p>

<h3 id="json-output">JSON Output</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Generate a JSON object with information about the following person.
The JSON should have these fields: name, age, occupation, skills (array).

Person description: John is a 34-year-old software engineer who knows Python, JavaScript, and database design.
</code></pre></div></div>

<h3 id="markdown-formatting">Markdown Formatting</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Create a markdown-formatted product description with:
- A level 2 heading with the product name
- A paragraph describing the product
- A bulleted list of features
- A level 3 heading for "Technical Specifications"
- A table with specifications

Product: Wireless noise-cancelling headphones with 30-hour battery life, Bluetooth 5.0, and memory foam ear cushions.
</code></pre></div></div>

<h3 id="custom-templates">Custom Templates</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Complete the following template with appropriate information:

TITLE: [Generate an engaging title]

SUMMARY: [Write a 2-3 sentence summary]

KEY POINTS:
1. [First main point]
2. [Second main point]
3. [Third main point]

CONCLUSION: [Write a brief conclusion]

Topic: The impact of artificial intelligence on healthcare
</code></pre></div></div>

<h2 id="6-model-evaluation">6. Model Evaluation</h2>

<p>Evaluate your customized model to ensure it meets your requirements:</p>

<h3 id="basic-evaluation-metrics">Basic Evaluation Metrics</h3>

<ol>
  <li><strong>Accuracy</strong>: Correctness of responses</li>
  <li><strong>Relevance</strong>: Response alignment with intent</li>
  <li><strong>Consistency</strong>: Reliability across similar inputs</li>
  <li><strong>Safety</strong>: Avoiding harmful or inappropriate content</li>
</ol>

<h3 id="evaluation-code-example">Evaluation Code Example</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load test dataset
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s">"json"</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s">"test_samples.json"</span><span class="p">)[</span><span class="s">"train"</span><span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">:</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"prompt"</span><span class="p">]</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"expected_response"</span><span class="p">]</span>
    
    <span class="c1"># Get model response (implementation depends on your setup)
</span>    <span class="n">response</span> <span class="o">=</span> <span class="n">get_model_response</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    
    <span class="c1"># Simple exact match evaluation
</span>    <span class="n">is_match</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="n">expected</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>
    
    <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s">"prompt"</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
        <span class="s">"expected"</span><span class="p">:</span> <span class="n">expected</span><span class="p">,</span>
        <span class="s">"response"</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
        <span class="s">"is_match"</span><span class="p">:</span> <span class="n">is_match</span>
    <span class="p">})</span>

<span class="c1"># Calculate accuracy
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="s">"is_match"</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Save detailed results
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"evaluation_results.json"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="next-steps">Next Steps</h2>

<p>Once you’ve mastered these basic customization techniques, you can:</p>

<ol>
  <li>Explore <a href="/ai-llm-blog/tutorials/advanced-features/">Advanced Features</a> for more sophisticated customization</li>
  <li>Learn about <a href="/ai-llm-blog/tutorials/ethical-considerations/">Ethical Considerations</a> when customizing AI models</li>
  <li>Review <a href="/ai-llm-blog/tutorials/advanced-features/optimization-strategies/">Performance Optimization Strategies</a> to ensure your customized AI runs efficiently in real-world scenarios.
Remember that effective customization is often iterative—start simple, evaluate results, and refine your approach based on feedback and performance metrics.</li>
</ol>

<h2 id="happy-customizing">Happy customizing!</h2>


        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2025-04-15T00:00:00+00:00">April 15, 2025</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/ai-llm-blog/tutorials/advanced-features/" class="pagination--pager" title="Advanced Features
">Previous</a>
    
    
      <a href="/ai-llm-blog/tutorials/ethical-considerations/" class="pagination--pager" title="Ethical Considerations When Customizing AI Models
">Next</a>
    
  </nav>

    </div>
  </article>

  

  
  

  <nav class="pagination">
    
      <a href="/tutorials/advanced-features/" class="prev">&laquo; Previous</a>
    

    
      <a href="/tutorials/ethical-considerations/" class="next">Next &raquo;</a>
    
  </nav>
  
</div>





      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/sednabcn" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/ruperto-p-bonet-chaple-8a26651b/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://twitter.com/BONETCHAPLE" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://www.instagram.com/RUPERTOPEDROBONET" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
        
          <li><a href="https://medium.com/@simleng" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-medium" aria-hidden="true"></i> Medium</a></li>
        
      
    

    
      <li><a href="/ai-llm-blog/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 <a href="https://sednabcn.github.io">AI, LLM & LLM-HypatiaX Blog</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.
<p>Site last built: 2025-05-05 22:13</p>
</div>


      </footer>
    </div>
    
  <script src="/ai-llm-blog/assets/js/main.min.js"></script>







  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FFJMQ3HXMK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FFJMQ3HXMK', { 'anonymize_ip': true});
</script>








    
  </body>
</html>
